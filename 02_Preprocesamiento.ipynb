{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcRkaiMbpEkXFQRJ+HDjJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rivero-Romero/Deep_Learning/blob/main/02_Preprocesamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHKOUC_iI1md"
      },
      "outputs": [],
      "source": [
        "# Install kaggle library\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload kaggle credential\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "tjL25mzWI97K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare kaggle environment\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "TyrmCtzFJC5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "!kaggle datasets download -d kaustubhb999/tomatoleaf"
      ],
      "metadata": {
        "id": "cB8Tf8rPJHPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tomatoleaf.zip"
      ],
      "metadata": {
        "id": "16FW6EuIJJMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/"
      ],
      "metadata": {
        "id": "nowv5ggfJWjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/tomatoleaf.zip -d /content/tomatoleaf"
      ],
      "metadata": {
        "id": "jDhYqNa7Jajh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/tomatoleaf"
      ],
      "metadata": {
        "id": "eXvIltXUJevD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!rm -rf Deep_Learning\n",
        "!git clone https://github.com/Rivero-Romero/Deep_Learning.git\n"
      ],
      "metadata": {
        "id": "oPdImCDKJfuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Deep_Learning\n"
      ],
      "metadata": {
        "id": "-EV1ybEIKhhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset_path = \"Deep_Learning/transformed_categories.csv\"\n",
        "dataset_df = pd.read_csv(dataset_path)\n",
        "dataset_df"
      ],
      "metadata": {
        "id": "YCk927djNNpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Converting labels from category to numeric\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "dataset_df[\"CATEGORY_BIN_ENCODED\"] = label_encoder.fit_transform(dataset_df[\"CATEGORY_BIN\"])\n",
        "dataset_df[[\"CATEGORY_BIN_ENCODED\", \"CATEGORY_BIN\"]].drop_duplicates()"
      ],
      "metadata": {
        "id": "_6YirhhYNV6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataframe columns into features\n",
        "y, x = dataset_df[\"CATEGORY_BIN_ENCODED\"], dataset_df[\"IMAGE_PATH\"]"
      ],
      "metadata": {
        "id": "Ot85ytfxODKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "from pathlib import Path\n",
        "\n",
        "# Definir las funciones de preprocesamiento\n",
        "\n",
        "def basic_preprocessing(path):\n",
        "    \"\"\"\n",
        "    Preprocesamiento básico: redimensionar y aplicar un filtro de mediana.\n",
        "    \"\"\"\n",
        "    target_resolution = (256, 256)\n",
        "    img_bgr = cv2.imread(path)\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    resize_image = cv2.resize(img_rgb, target_resolution)\n",
        "    denoised_image = cv2.medianBlur(resize_image, 3)\n",
        "    return denoised_image\n",
        "\n",
        "def remove_median(path):\n",
        "    \"\"\"\n",
        "    Preprocesamiento que resalta las diferencias respecto a la mediana de la imagen.\n",
        "    \"\"\"\n",
        "    image = basic_preprocessing(path)\n",
        "    return abs(image - np.median(image))\n",
        "\n",
        "def scaling(path):\n",
        "    \"\"\"\n",
        "    Preprocesamiento que centra la imagen y la normaliza.\n",
        "    \"\"\"\n",
        "    image = basic_preprocessing(path)\n",
        "    image_center = image.astype(np.float) - np.median(image)\n",
        "    max_val = image_center.max()\n",
        "    min_val = image_center.min()\n",
        "    factor = 1 / (max_val - min_val)\n",
        "    processed = factor * image_center\n",
        "    return processed\n",
        "\n",
        "def preprocess_images(image_paths, preprocessing_function):\n",
        "    \"\"\"\n",
        "    Preprocesar un conjunto de imágenes usando una función de preprocesamiento dada.\n",
        "    \"\"\"\n",
        "    processed_images = []\n",
        "    for path in image_paths:\n",
        "        processed_image = preprocessing_function(path)\n",
        "        processed_images.append(processed_image)\n",
        "    return processed_images\n",
        "\n",
        "# Crear una lista con las rutas de las imágenes\n",
        "image_paths = dataset_df['IMAGE_PATH'].tolist()\n",
        "\n",
        "# Aplicar preprocesamiento a las imágenes utilizando multiprocessing (en paralelo)\n",
        "def parallel_preprocessing(image_paths, preprocessing_function, num_processes=4):\n",
        "    \"\"\"\n",
        "    Preprocesar las imágenes en paralelo.\n",
        "    \"\"\"\n",
        "    chunk_size = len(image_paths) // num_processes\n",
        "    chunks = [image_paths[i:i + chunk_size] for i in range(0, len(image_paths), chunk_size)]\n",
        "\n",
        "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
        "        results = pool.starmap(preprocess_images, [(chunk, preprocessing_function) for chunk in chunks])\n",
        "\n",
        "    # Unir los resultados de los diferentes procesos\n",
        "    return [image for result in results for image in result]\n",
        "\n",
        "# Usar multiprocessing para preprocesar las imágenes con 'basic_preprocessing'\n",
        "preprocessed_images = parallel_preprocessing(image_paths, basic_preprocessing, num_processes=4)\n",
        "\n",
        "#Mostrar una imagen procesada\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(preprocessed_images[0])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3ibH-a85OHLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15"
      ],
      "metadata": {
        "id": "Bo_-BKGzQ3N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, image_paths, labels, batch_size, function, scaling = 255.0):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.function = function\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        self.scaling = scaling\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = (index + 1) * self.batch_size\n",
        "\n",
        "        batch_image_paths = self.image_paths[start:end]\n",
        "        batch_labels = self.labels[start:end]\n",
        "\n",
        "        batch_images = [self.function(image_path) for image_path in batch_image_paths]\n",
        "        batch_images = np.array(batch_images) / self.scaling  # Normalize pixel values\n",
        "\n",
        "        return batch_images, np.array(batch_labels)"
      ],
      "metadata": {
        "id": "Ra_xFkiqPv7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Mostrar ejemplo de imagen con preprocesamiento\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# 'basic_preprocessing' realiza la carga, cambio de tamaño y filtro de mediana a la imagen\n",
        "\n",
        "data_generator = CustomDataGenerator(\n",
        "      dataset_df[\"IMAGE_PATH\"].values,  # Rutas de las imágenes\n",
        "      dataset_df[\"CATEGORY_BIN\"].values,  # Etiquetas\n",
        "      batch_size,\n",
        "      basic_preprocessing  # Función de preprocesamiento\n",
        "    )\n",
        "\n",
        "sample_index = 16  # El índice de la imagen a mostrar\n",
        "batch_id = 0\n",
        "index_data = 0\n",
        "\n",
        "# Extraer la imagen procesada del generador\n",
        "sample_image = data_generator[batch_id][index_data][sample_index]\n",
        "\n",
        "# Preparar la imagen sin procesar (raw) y la procesada (denoised) para mostrar\n",
        "sample_images = [\n",
        "    (cv2.cvtColor(cv2.imread(dataset_df[\"IMAGE_PATH\"].iloc[sample_index]), cv2.COLOR_BGR2RGB), \"Raw Image\"),  # Imagen sin procesar\n",
        "    (sample_image, \"Preprocessed Image\")  # Imagen procesada\n",
        "]\n",
        "\n",
        "# Crear los subgráficos para mostrar ambas imágenes\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1 fila y 2 columnas\n",
        "\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    image, title = sample_images[i]\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(title)\n",
        "    ax.axis('off')  # Ocultamos los ejes para una visualización más limpia\n",
        "\n",
        "plt.tight_layout()  # Ajusta los márgenes automáticamente para que no se superpongan\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b90bghd9SOBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "# Asegúrate de que estas funciones de preprocesamiento estén definidas en tu código\n",
        "def basic_preprocessing(path):\n",
        "    target_resolution = (256, 256)\n",
        "    img_bgr = cv2.imread(path)\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    resize_image = cv2.resize(img_rgb, target_resolution)\n",
        "    denoised_image = cv2.medianBlur(resize_image, 3)\n",
        "    return denoised_image\n",
        "\n",
        "\n",
        "def remove_median(path):\n",
        "    # Preprocesamiento basado en la mediana\n",
        "    image = basic_preprocessing(path)\n",
        "    return abs(image - np.median(image))\n",
        "\n",
        "# Definición de generador de datos personalizado\n",
        "class CustomDataGenerator(Sequence):\n",
        "    def __init__(self, image_paths, labels, batch_size, function, scaling=255.0):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.function = function\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        self.scaling = scaling\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = (index + 1) * self.batch_size\n",
        "\n",
        "        batch_image_paths = self.image_paths[start:end]\n",
        "        batch_labels = self.labels[start:end]\n",
        "\n",
        "        batch_images = [self.function(image_path) for image_path in batch_image_paths]\n",
        "        batch_images = np.array(batch_images) / self.scaling  # Normalización\n",
        "\n",
        "        return batch_images, np.array(batch_labels)\n",
        "\n",
        "# Cargando tus datos de imágenes y etiquetas desde el DataFrame (suponiendo que ya tienes estas columnas)\n",
        "image_paths = dataset_df[\"IMAGE_PATH\"].tolist()  # Ruta de las imágenes\n",
        "labels = dataset_df[\"CATEGORY_BIN\"].tolist()     # Etiquetas de las categorías (enfermedad/no enfermedad)\n",
        "\n",
        "# Creando el generador de datos con el preprocesamiento adecuado\n",
        "batch_size = 32\n",
        "data_generator = CustomDataGenerator(\n",
        "    image_paths,\n",
        "    labels,\n",
        "    batch_size,\n",
        "    remove_median  # Usando la función de preprocesamiento \"remove_median\"\n",
        ")\n",
        "\n",
        "# Mostrar ejemplo de imagen procesada\n",
        "sample_index = 16\n",
        "batch_id = 0\n",
        "index_data = 0\n",
        "sample_image = data_generator[batch_id][index_data][sample_index]\n",
        "\n",
        "# Crear los subgráficos para comparar\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "# Mostrar la imagen original y la imagen procesada\n",
        "sample_images = [\n",
        "    (cv2.cvtColor(cv2.imread(dataset_df[\"IMAGE_PATH\"].loc[sample_index]), cv2.COLOR_BGR2RGB), \"Raw Image\"),  # Imagen original\n",
        "    (sample_image, \"Image Without Median\")  # Imagen después de aplicar el preprocesamiento\n",
        "]\n",
        "\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    image, title = sample_images[i]\n",
        "    ax.imshow(image, cmap=\"gray\")  # Usar escala de grises para resaltar detalles\n",
        "    ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9PruNNL2S6vW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}